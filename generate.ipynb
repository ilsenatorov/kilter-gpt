{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.gpt import GPTModel\n",
    "from src.utils import Tokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "from src.utils import Plotter\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the model weights and init the model\n",
    "run = wandb.init()\n",
    "artifact = run.use_artifact(\"ilsenatorov/kilter-gpt/model-17j5ahs6:v0\", type=\"model\")\n",
    "artifact_dir = artifact.download()\n",
    "\n",
    "model = GPTModel.load_from_checkpoint(artifact_dir + \"/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the plotter and tokenizer\n",
    "plotter = Plotter()\n",
    "tokenizer = Tokenizer.load(\"data/tokenizer.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt and plot the holds from the prompt\n",
    "hold_prompt = \"p1136r12p1383r14\"\n",
    "prompts = [\n",
    "    (hold_prompt, 30, \"5a\"),\n",
    "    (hold_prompt, 30, \"6a\"),\n",
    "    (hold_prompt, 30, \"7a\"),\n",
    "    (hold_prompt, 30, \"8a\"),\n",
    "]\n",
    "plotter.plot_climb(hold_prompt, True)\n",
    "# tokenize, remove EOS token, pad left\n",
    "tokenized_prompts = torch.stack(\n",
    "    [tokenizer.pad(tokenizer.encode(*x)[:-1], model.config.context_len) for x in prompts]\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# higher temperature -> more randomness. 0.2 is a good value for this model\n",
    "TEMP = 0.2\n",
    "generated = model.generate(tokenized_prompts, 50, temperature=TEMP)\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15, 4))  # 2 rows, 2 columns\n",
    "\n",
    "for i, z in enumerate(tokenizer.decode_batch(generated)):\n",
    "    frames, angle, grade = tokenizer.clean(z)\n",
    "\n",
    "    axs[i].imshow(plotter.plot_climb(frames))\n",
    "    axs[i].set_title(f\"{grade} @ {angle[1:]}Â°\")\n",
    "    axs[i].axis(\"off\")  # Remove axis ticks and labels\n",
    "\n",
    "fig.suptitle(f\"Temp: {TEMP}\")\n",
    "plt.tight_layout()  # Adjust spacing for better layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
